<div class="text_body">
  <h2>Limitations and Future work</h2>
  <p>
    <strong>Optimized strategies:</strong>
    The creative strategies were effective but arbitrarily created and there was
    no thorough evaluation of their ideal structure or content. This sets the stage
    for potentially co-evolving strategies alongside artifacts that adapt to specific
    domains. These evolved "chain of creative thought templates" could even be reusable
    in direct prompting.
  </p>
  <p>
    <strong>Quality and Constraints:</strong>
    This algorithm fails to produce valid outputs when any constraints are innately
    satisfied by the prompt, but does not have a way to repair infeasible solutions
    or any kind of minimal criteria. Potential improvements could be to apply a minimal
    criteria to the reproducing population or use the multimodal qualities of the
    models to "see" the outputs via image inputs. At the time of writing this, image
    capacities were not yet available in the o3-api, but this will likely change
    soon. Potentially - if costs lower - the entire population could be provided
    together as images allowing pressure to be applied from the phenotypes (images)
    instead of the summaries of genomes (text).
  </p>
  <p>
    <strong>Concept / Implementation barrier:</strong>
    Large outputs become costly to generate for every generation, an alternative
    approach is to only generate a shorter description of the central idea for the
    object and then do a run with a more powerful model for the final generations.
    Analogies to how most projects get evaluated at the concept phase. The main challenge
    is that many concepts generated by the LLM are impractical, diverge greatly when
    generated or are hard to articulate (such as shaders which are hard to describe
    in text). Potential future work could look to bridge this gap.
  </p>
</div>
